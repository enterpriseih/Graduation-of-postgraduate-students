% !Mode:: "TeX:UTF-8"

\chapter{图像分割}

\section{超像素相似度}
在获得超像素之后，我们需要测量它们之间的相似性。超像素的特征可以用超像素池来计算，它实际上是计算属于某个超像素的像素特征的平均值。在我们的算法中，当执行超像素池时，我们使用了不同于在超像素生成中使用的像素特征，如图3-1所示，使用浅蓝色矩形所表示的图像特征。其背后的原因是，超像素不包含语义信息，而图像分割却包含语义信息，因此这两种任务的特征是不同的。我们在实验中通过比较超像素和图像分割的结果以及该算法的一个变体（ours-conv7）来验证这一思想。参考第4.1了解更多细节。

获取超像素后，我们假设超像素的数量为M，将超像素集合表示为$\mathcal{S}=\{S_{1},S_{2},\cdots ,S_{m}\}$，根据图3-1所示，我们所得到的超像素进行超像素池化操作，得到对应超像素的特征向量$\{ v_{1},v_{2},\cdots,v_{m}\}$。超像素池化操作表示如下：
\begin{equation}
v_{i} = \frac{1}{|S_{i}|}\sum_{p\in S_{i} }F'_{p},
\end{equation}
其中，$F'_{p}$ 表示在超像素池中使用的像素$p$的特征向量。

相邻超像素i和超像素j的相似度可以由如下公式获得：
\begin{equation}\label{eqn:sim}
s_{ij} = \frac{2}{1+{\rm exp}\left ( \left \| v_{i}-v_{j}\right \|_{1}\right )},
\end{equation}

其中$s_{ij}$的范围是$[0,1]$。$s_{ij}$值越大，超像素$i$和$j$的相似性越高。当$v_{i}$和$v_{j}$非常相似时，$s_{ij}$接近1，相反，当$v_{i}$和$v_{j}$极为不同时，它接近于0。我们根据相似度$s_{ij}$决定是否合并超像素$i$和$j$。

\section{损失函数}

我们假设同一分割区域内的超像素对之间的相似性大于不同分割区域中的超像素对的相似性。基于（3-6）中定义的相似性度量，我们定义的损失函数如下：
\begin{equation}
\begin{split}
 L =  - \sum_{S_{i}\in S}\sum_{S_{j}\in \mathcal{R}_{i}}   \left[   { \left(
 1  -\alpha  \right)\cdot l_{ij}\cdot \log \left( s_{ij} \right)  } \right. \\
 \left. {  + \alpha \cdot \left( 1-l_{ij}\right) \cdot \log \left( 1- s_{ij}\right)  }   \right],
 \label{equation.6}
\end{split}
\end{equation}
其中$\mathcal{R}_{i}$是超像素$S_{i}$的相邻的超像素集合，$S_i$表示$S_i$和$S_j$是否属于同一个分割区域。在实际应用中，$l_{ij}$ 是由所获得的超像素集和数据集提供的真值来计算的。在$S_i$和$S_i$属于同一分割区域的情况下，$l_{ij} = 1$；否则，$l_{ij} = 0$。

注意，对于不同的输入图像，$l_{ij}$ 的矩阵是不同的。因此，训练阶段的小批量大小必须设置为1，即一次只向网络中输入一张图像。参数$\alpha$表示在真值中属于同一区域的超像素对的比例，用于平衡正样本和负样品。通过将$|Y_+|$ 表示为属于同一区域的超像素对的数目，将$|Y|$表示为超级像素对的总数，通过$\alpha  = \left | Y_{+}\right | / \left | Y \right |$ 来计算。通过反向传播，图像分割也指导了超像素分割。

\section{超像素融合}

通过合并相似的超像素得到最终的图像分割。我们利用相邻超像素之间的相似性和一个预先设定的阈值T来确定两个相邻超像素是否合并。算法1概述了超像素合并的计算步骤。
\begin{algorithm}[h]
  \caption{Superpixel merging algorithm}
  \textbf{Input}: $s$ : similarity;
  \hspace*{2em} $T$ : similarity threshold;\\
  \hspace*{2.5em} $\mathcal{S}=\{S_{1}, S_{2},\cdots, S_{m}\}$ : superpixels.\\
  \textbf{Output}: Segmentation $\mathcal{S}$.
  \begin{algorithmic}[1]
    \For{each $S_{i}\in \mathcal{S}$}
    \State Construct adjacent superpixel set $\mathcal{R}_{i}\subset \mathcal{S}$ of $S_i$;
        \For{each $S_{j}\in R_{i}$}
            \If {$s_{ij} > T$}
                \State$S_{i} \gets S_{i}\cup S_{j}$, $\mathcal{S} \gets \mathcal{S} \setminus S_{j}$ ;
                \State Update $\mathcal{R}_i$ ;
            \EndIf
        \EndFor
    \EndFor
    \label{algorithm1}
  \end{algorithmic}
\end{algorithm}

\section{网络结构}

图3-1显示了我们的网络结构。用于特征提取的CNN网络由卷积层、组规范化(GN)和ReLU激活函数组成。我们将GN中的组数设置为8。在第2层和第4层卷积后，我们使用最大池来增加感受野。对第4层和第6层的输出进行采样，然后与第2层的输出连接，以丰富提取的特征。我们使用3$\times $3卷积滤波器将输出通道设置为每层64个。

注意，考虑到网络中每个小批量的大小必须为1，我们用GN替换了广泛使用的批处理规范化(BN)层。BN操作是深度学习发展中的一个里程碑式的技术，使各种网络能够进行训练。然而，沿着批处理维度进行规范化会带来问题——当批处理大小变小时，BN的错误会迅速增加，这是由于批次统计估计不准确造成的。相反，GN将通道分成组，并计算每组中的均值和方差进行归一化。GN的计算是独立于批量大小的，其精度在较大的批量范围内是稳定的。在实验中，我们还比较了用BN和GN作为归一化的结果。

在多任务学习中，不同层次的任务需要不同的图像特征，如supernet。对于超像素生成和图像分割这两个不同层次的任务，我们进一步对上一步得到的图像特征进行卷积运算，得到不同的特征向量，以满足不同任务的需要。具体来说，对于超像素生成任务，我们使用核大小为3$\times $3的卷积层来获得30个通道的特征向量。对于图像分割任务，我们首先对256个输出通道进行3$\times $3卷积运算，然后使用1$\times $1卷积核得到64个通道的特征向量。如图3-1所示，我们将得到的特征向量分别输入到后续的可微聚类算法模块和超像素池层，然后利用所提出的相应的损失函数对网络进行训练。

\section{实施细节}

我们基于Caffe框架来搭建神经网络，这是一个非常有效的深度学习框架，广泛应用于学术界和工业界。所有代码都是用C++和Python包装编写的。

对于超级像素的生成，就像在原始的SLIC算法中一样，我们在(3-4)之后的每个超级像素簇内的像素之间加强空间连通性。通过将小于某个阈值的超像素与周围的超级像素合并，然后为每个空间连接的组件分配一个唯一的聚类ID来实现的。对于图像分割，我们在合并后进行空间连通性增强操作。需要注意的是，加强空间连通性的运算是不可微的，我们只把它当作后处理，而不加入神经网络。

我们使用BSDS500数据集作为我们的训练和测试数据，该数据集已在图像分割领域得到广泛应用。由于BSDS500中训练样本数量较少，训练时需要进行数据扩充。我们将每一个真值作为一个单独的样本，即对于每一对图像和真值，我们将其作为训练样本提供给网络。通过这种方式，我们得到了1633对训练/验证对和1063对测试对。另外，我们采用了两种常用的数据扩充策略，即翻转和裁剪。具体地说，在训练阶段，我们将图像左右翻转，随机地将图像裁剪成201$\times $201大小的图像块，进行数据增强。采用Adam优化我们的网络。基本学习率设置为1e-5，生成的超级像素数设置为100。动量设置为0.99，以在相对较小规模的数据上实现稳定优化，如FCN 中所建议的那样。如第3.5，每个小批量的大小设置为1。

我们进行500K次迭代来训练深度学习模型，并根据验证的准确性选择最终的训练模型。

